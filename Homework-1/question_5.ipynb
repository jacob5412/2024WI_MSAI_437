{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d8b9eb0>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from utilities.data_loader import load_data\n",
    "from utilities.data_formater import format_data\n",
    "from models.mlp_model_torch import NeuralNetwork\n",
    "from training_testing.regularization_testing import train_and_evaluate_model\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare your dataset\n",
    "X_train, y_train = load_data(\"data/center_surround_train.csv\")\n",
    "X_valid, y_valid = load_data(\"data/center_surround_valid.csv\")\n",
    "X_test, y_test = load_data(\"data/center_surround_test.csv\")\n",
    "\n",
    "# Reshape targets if needed\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_valid = y_valid.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = format_data(X_train, y_train)\n",
    "valid_dataset = format_data(X_valid, y_valid)\n",
    "test_dataset = format_data(X_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your data into PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_valid_tensor = torch.FloatTensor(X_valid)\n",
    "y_valid_tensor = torch.FloatTensor(y_valid)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Wrap them in DataLoader\n",
    "batch_size = 64  # Adjust as needed\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with L2 Regularization (Weight Decay)\n",
      "Train Loss: 0.0756, Train Accuracy: 30.8800\n",
      "Valid Loss: 0.1036, Valid Accuracy: 31.1600\n",
      "Test Loss: 0.1901, Test Accuracy: 30.0400\n",
      "\n",
      "Training with L1 Regularization\n",
      "Train Loss: 0.0784, Train Accuracy: 30.8800\n",
      "Valid Loss: 0.1111, Valid Accuracy: 31.1600\n",
      "Test Loss: 0.1825, Test Accuracy: 30.0400\n",
      "\n",
      "Training with Dropout\n",
      "Train Loss: 0.1066, Train Accuracy: 31.1600\n",
      "Valid Loss: 0.0657, Valid Accuracy: 31.1600\n",
      "Test Loss: 0.1867, Test Accuracy: 30.0400\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = 15\n",
    "output_size = 1\n",
    "num_epochs = 400\n",
    "\n",
    "print(\"Training with L2 Regularization (Weight Decay)\")\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "train_and_evaluate_model(model, criterion, optimizer, train_loader, valid_loader, test_loader, num_epochs)\n",
    "\n",
    "\n",
    "# L1 Regularization\n",
    "print(\"\\nTraining with L1 Regularization\")\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # No weight_decay here for L1\n",
    "train_and_evaluate_model(model, criterion, optimizer, train_loader, valid_loader, test_loader, num_epochs, l1_strength=1e-5)\n",
    "\n",
    "\n",
    "# Dropout\n",
    "print(\"\\nTraining with Dropout\")\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size, dropout_rate=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # No weight_decay necessary for Dropout\n",
    "train_and_evaluate_model(model, criterion, optimizer, train_loader, valid_loader, test_loader, num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
